{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "313ab865-1bf7-4ed7-9f70-4329d46499e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be3e2857-7090-4805-a180-7805af59b0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Text Language  word_count  character_count  word_density  \\\n",
      "0             தமிழ்நாடு    Tamil           1                9      0.100000   \n",
      "1  செய்தி தமிழ் இது ஒரு    Tamil           4               17      0.222222   \n",
      "2                நன்றி!    Tamil           1                6      0.142857   \n",
      "3              வணக்கம்!    Tamil           1                8      0.111111   \n",
      "4           மொழி தமிழ்?    Tamil           2               10      0.181818   \n",
      "\n",
      "   punc_count  num_vowels  vowel_density  num_exclamation_marks  \\\n",
      "0           0           0            0.0                      0   \n",
      "1           0           0            0.0                      0   \n",
      "2           1           0            0.0                      1   \n",
      "3           1           0            0.0                      1   \n",
      "4           1           0            0.0                      0   \n",
      "\n",
      "   num_question_marks  num_punctuation  num_unique_words  num_repeated_words  \\\n",
      "0                   0                0                 1                   0   \n",
      "1                   0                0                 4                   0   \n",
      "2                   0                1                 1                   0   \n",
      "3                   0                1                 1                   0   \n",
      "4                   1                1                 2                   0   \n",
      "\n",
      "   words_vs_unique  \n",
      "0              1.0  \n",
      "1              1.0  \n",
      "2              1.0  \n",
      "3              1.0  \n",
      "4              1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "# File path to the CSV file\n",
    "file_path = \"C:/Users/Suhas sattigeri/Desktop/Mini P/data/dataset2.csv\"\n",
    "\n",
    "# Load the dataset with utf-8 encoding\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Remove null values for the \"Text\" column\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "# Convert the column \"Text\" to string type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "# Convert the column \"Language\" to string type\n",
    "df['Language'] = df['Language'].astype(str)\n",
    "\n",
    "# Define punctuation and vowels\n",
    "punc = ('.', ',', '!', '?', ';', ':', '-', '(', ')', '[', ']', '{', '}', \"'\", '\"')\n",
    "vowels = 'AEIOUaeiou'\n",
    "\n",
    "# Feature engineering\n",
    "df['word_count'] = df['Text'].apply(lambda x: len(x.split()))\n",
    "df['character_count'] = df['Text'].apply(lambda x: len(x.replace(\" \", \"\")))\n",
    "df['word_density'] = df['word_count'] / (df['character_count'] + 1)\n",
    "df['punc_count'] = df['Text'].apply(lambda x: len([a for a in x if a in punc]))\n",
    "df['num_vowels'] = df['Text'].apply(lambda x: sum([1 for a in x if a in vowels]))\n",
    "df['vowel_density'] = df['num_vowels'] / df['word_count']\n",
    "df['num_exclamation_marks'] = df['Text'].apply(lambda x: x.count('!'))\n",
    "df['num_question_marks'] = df['Text'].apply(lambda x: x.count('?'))\n",
    "df['num_punctuation'] = df['Text'].apply(lambda x: sum(x.count(w) for w in punc))\n",
    "df['num_unique_words'] = df['Text'].apply(lambda x: len(set(w for w in x.split())))\n",
    "df['num_repeated_words'] = df['Text'].apply(lambda x: len([w for w in collections.Counter(x.split()).values() if w > 1]))\n",
    "df['words_vs_unique'] = df['num_unique_words'] / df['word_count']\n",
    "\n",
    "# Display the first few rows of the dataframe to check the new features\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b04a1bb1-4606-4944-acaf-be95ef57d01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language                 Kannada      Tamil     Telugu\n",
      "word_count              1.895091   2.042764   2.072079\n",
      "character_count        10.073040  12.129875  11.034653\n",
      "word_density            0.173298   0.160330   0.176511\n",
      "punc_count              0.397862   0.394179   0.395644\n",
      "num_vowels              0.000000   0.000000   0.000000\n",
      "vowel_density           0.000000   0.000000   0.000000\n",
      "num_exclamation_marks   0.200911   0.192239   0.204356\n",
      "num_question_marks      0.196952   0.201940   0.191287\n",
      "num_punctuation         0.397862   0.394179   0.395644\n",
      "num_unique_words        1.895091   2.042764   2.072079\n",
      "num_repeated_words      0.000000   0.000000   0.000000\n",
      "words_vs_unique         1.000000   1.000000   1.000000\n",
      "                       word_count  character_count  word_density  punc_count  \\\n",
      "word_count               1.000000         0.659805      0.468209    0.316843   \n",
      "character_count          0.659805         1.000000     -0.300911    0.303741   \n",
      "word_density             0.468209        -0.300911      1.000000    0.052074   \n",
      "punc_count               0.316843         0.303741      0.052074    1.000000   \n",
      "num_vowels                    NaN              NaN           NaN         NaN   \n",
      "vowel_density                 NaN              NaN           NaN         NaN   \n",
      "num_exclamation_marks    0.197949         0.186162      0.036151    0.616036   \n",
      "num_question_marks       0.190917         0.186640      0.027744    0.611316   \n",
      "num_punctuation          0.316843         0.303741      0.052074    1.000000   \n",
      "num_unique_words         1.000000         0.659805      0.468209    0.316843   \n",
      "num_repeated_words            NaN              NaN           NaN         NaN   \n",
      "words_vs_unique               NaN              NaN           NaN         NaN   \n",
      "\n",
      "                       num_vowels  vowel_density  num_exclamation_marks  \\\n",
      "word_count                    NaN            NaN               0.197949   \n",
      "character_count               NaN            NaN               0.186162   \n",
      "word_density                  NaN            NaN               0.036151   \n",
      "punc_count                    NaN            NaN               0.616036   \n",
      "num_vowels                    NaN            NaN                    NaN   \n",
      "vowel_density                 NaN            NaN                    NaN   \n",
      "num_exclamation_marks         NaN            NaN               1.000000   \n",
      "num_question_marks            NaN            NaN              -0.246797   \n",
      "num_punctuation               NaN            NaN               0.616036   \n",
      "num_unique_words              NaN            NaN               0.197949   \n",
      "num_repeated_words            NaN            NaN                    NaN   \n",
      "words_vs_unique               NaN            NaN                    NaN   \n",
      "\n",
      "                       num_question_marks  num_punctuation  num_unique_words  \\\n",
      "word_count                       0.190917         0.316843          1.000000   \n",
      "character_count                  0.186640         0.303741          0.659805   \n",
      "word_density                     0.027744         0.052074          0.468209   \n",
      "punc_count                       0.611316         1.000000          0.316843   \n",
      "num_vowels                            NaN              NaN               NaN   \n",
      "vowel_density                         NaN              NaN               NaN   \n",
      "num_exclamation_marks           -0.246797         0.616036          0.197949   \n",
      "num_question_marks               1.000000         0.611316          0.190917   \n",
      "num_punctuation                  0.611316         1.000000          0.316843   \n",
      "num_unique_words                 0.190917         0.316843          1.000000   \n",
      "num_repeated_words                    NaN              NaN               NaN   \n",
      "words_vs_unique                       NaN              NaN               NaN   \n",
      "\n",
      "                       num_repeated_words  words_vs_unique  \n",
      "word_count                            NaN              NaN  \n",
      "character_count                       NaN              NaN  \n",
      "word_density                          NaN              NaN  \n",
      "punc_count                            NaN              NaN  \n",
      "num_vowels                            NaN              NaN  \n",
      "vowel_density                         NaN              NaN  \n",
      "num_exclamation_marks                 NaN              NaN  \n",
      "num_question_marks                    NaN              NaN  \n",
      "num_punctuation                       NaN              NaN  \n",
      "num_unique_words                      NaN              NaN  \n",
      "num_repeated_words                    NaN              NaN  \n",
      "words_vs_unique                       NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Ensure all columns used for mean calculation are numerical\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Group by 'language' and calculate the mean, then transpose the result\n",
    "mean_by_language = df.groupby('Language')[numeric_columns].mean().T\n",
    "\n",
    "# Display the transposed result\n",
    "print(mean_by_language)\n",
    "\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the Pearson correlation matrix for numeric columns\n",
    "correlation_matrix = numeric_df.corr(method='pearson')\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2b5cd-ef11-407f-add6-74bfbf30154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49b0850f-cc8d-4ec0-a5a0-afdd85e80f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Split the dataset into features and target variable\n",
    "# Load the dataset with utf-8 encoding\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Remove null values for the \"text\" column\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "# Convert the column \"text\" to string type\n",
    "df['text'] = df['Text'].astype(str)\n",
    "\n",
    "# Convert the column \"language\" to string type\n",
    "df['Language'] = df['Language'].astype(str)\n",
    "\n",
    "# Remove rows where the text is empty or only whitespace\n",
    "df = df[df['Text'].str.strip() != '']\n",
    "\n",
    "# Features and labels\n",
    "X = df['Text']\n",
    "y = df['Language']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f7b654d-2287-4b9a-aca1-dbfc7d4af82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7733421313097988\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      0.86      0.92      1039\n",
      "       Tamil       0.58      1.00      0.73       944\n",
      "      Telugu       1.00      0.49      0.65      1048\n",
      "\n",
      "    accuracy                           0.77      3031\n",
      "   macro avg       0.86      0.78      0.77      3031\n",
      "weighted avg       0.87      0.77      0.77      3031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8423fe63-206b-4f5b-bab3-8276e339a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "Accuracy: 0.7733421313097988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      0.86      0.92      1039\n",
      "       Tamil       0.58      1.00      0.73       944\n",
      "      Telugu       1.00      0.49      0.65      1048\n",
      "\n",
      "    accuracy                           0.77      3031\n",
      "   macro avg       0.86      0.78      0.77      3031\n",
      "weighted avg       0.87      0.77      0.77      3031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40a03979-8fb3-4f99-94f4-e94a68a23ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9313757835697789\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      0.86      0.92      1039\n",
      "       Tamil       1.00      0.94      0.97       944\n",
      "      Telugu       0.83      1.00      0.91      1048\n",
      "\n",
      "    accuracy                           0.93      3031\n",
      "   macro avg       0.94      0.93      0.93      3031\n",
      "weighted avg       0.94      0.93      0.93      3031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dt = dt_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nDecision Tree Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b219b792-b1d6-48be-815f-bfea04f8b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ಕನ್ನಡವೇನು\n",
      "Naive Bayes Prediction: Tamil\n",
      "Decision Tree Prediction: Telugu\n",
      "\n",
      "Text: தமிழ்நாடு\n",
      "Naive Bayes Prediction: Tamil\n",
      "Decision Tree Prediction: Telugu\n",
      "\n",
      "Text: తెలుగు భాష\n",
      "Naive Bayes Prediction: Tamil\n",
      "Decision Tree Prediction: Telugu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example new text data\n",
    "new_texts = [\"ಕನ್ನಡವೇನು\", \"தமிழ்நாடு\", \"తెలుగు భాష \"]  # Ensure texts are representative\n",
    "\n",
    "# Convert the new text data to a DataFrame\n",
    "new_df = pd.DataFrame(new_texts, columns=['Text'])\n",
    "\n",
    "# Preprocess the new text data (consistent with training preprocessing)\n",
    "new_df['Text'] = new_df['Text'].str.lower().str.replace(\"[^\\w\\s]\", \"\", regex=True)\n",
    "new_df = new_df[new_df['Text'].str.strip() != '']  # Keep non-empty texts only\n",
    "\n",
    "# Transform the new text data using the same TF-IDF vectorizer\n",
    "new_texts_tfidf = vectorizer.transform(new_df['Text'])\n",
    "\n",
    "# Predict using Naive Bayes model\n",
    "nb_predictions = nb_model.predict(new_texts_tfidf)\n",
    "\n",
    "# Predict using Decision Tree model\n",
    "dt_predictions = dt_model.predict(new_texts_tfidf)\n",
    "\n",
    "# Print the predictions\n",
    "for i, text in enumerate(new_texts):\n",
    "    print(f\"Text: {text.strip()}\")\n",
    "    print(f\"Naive Bayes Prediction: {nb_predictions[i]}\")\n",
    "    print(f\"Decision Tree Prediction: {dt_predictions[i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b92ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f642c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      1.00      1.00      1039\n",
      "       Tamil       1.00      1.00      1.00       944\n",
      "      Telugu       1.00      1.00      1.00      1048\n",
      "\n",
      "    accuracy                           1.00      3031\n",
      "   macro avg       1.00      1.00      1.00      3031\n",
      "weighted avg       1.00      1.00      1.00      3031\n",
      "\n",
      "\n",
      "Decision Tree Classifier\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      1.00      1.00      1039\n",
      "       Tamil       1.00      1.00      1.00       944\n",
      "      Telugu       1.00      1.00      1.00      1048\n",
      "\n",
      "    accuracy                           1.00      3031\n",
      "   macro avg       1.00      1.00      1.00      3031\n",
      "weighted avg       1.00      1.00      1.00      3031\n",
      "\n",
      "Text: ಕನ್ನಡವೇನು\n",
      "Naive Bayes Prediction: Kannada\n",
      "Decision Tree Prediction: Kannada\n",
      "\n",
      "Text: தமிழ்நாடு\n",
      "Naive Bayes Prediction: Tamil\n",
      "Decision Tree Prediction: Tamil\n",
      "\n",
      "Text: తెలుగు భాష\n",
      "Naive Bayes Prediction: Telugu\n",
      "Decision Tree Prediction: Telugu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset with utf-8 encoding\n",
    "file_path = 'C:/Users/Suhas sattigeri/Desktop/Mini P/data/dataset2.csv'\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Remove null values for the \"Text\" column\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "# Convert the column \"Text\" to string type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "# Convert the column \"Language\" to string type\n",
    "df['Language'] = df['Language'].astype(str)\n",
    "\n",
    "# Preprocess the text (lowercase and remove punctuation)\n",
    "df['Text'] = df['Text'].str.lower().str.replace(\"[^\\w\\s]\", \"\", regex=True)\n",
    "\n",
    "# Remove rows with empty text after preprocessing\n",
    "df = df[df['Text'].str.strip() != '']\n",
    "\n",
    "# Feature engineering\n",
    "df['word_count'] = df['Text'].apply(lambda x: len(x.split()))\n",
    "df['character_count'] = df['Text'].apply(lambda x: len(x.replace(\" \", \"\")))\n",
    "df['word_density'] = df['word_count'] / (df['character_count'] + 1)\n",
    "df['punc_count'] = df['Text'].apply(lambda x: len([a for a in x if a in '.,!?;:()[]{}\\'\"']))\n",
    "df['num_vowels'] = df['Text'].apply(lambda x: sum([1 for a in x if a in 'aeiou']))\n",
    "df['vowel_density'] = df['num_vowels'] / df['word_count']\n",
    "df['num_unique_words'] = df['Text'].apply(lambda x: len(set(x.split())))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X = df['Text']\n",
    "y = df['Language']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "y_pred_dt = dt_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the models\n",
    "print(\"Naive Bayes Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"\\nDecision Tree Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Example new text data\n",
    "new_texts = [\"ಕನ್ನಡವೇನು\", \"தமிழ்நாடு\", \"తెలుగు భాష \"]  # Ensure texts are representative\n",
    "\n",
    "# Convert the new text data to a DataFrame\n",
    "new_df = pd.DataFrame(new_texts, columns=['Text'])\n",
    "\n",
    "# Preprocess the new text data (consistent with training preprocessing)\n",
    "new_df['Text'] = new_df['Text'].str.lower().str.replace(\"[^\\w\\s]\", \"\", regex=True)\n",
    "new_df = new_df[new_df['Text'].str.strip() != '']  # Keep non-empty texts only\n",
    "\n",
    "# Transform the new text data using the same TF-IDF vectorizer\n",
    "new_texts_tfidf = vectorizer.transform(new_df['Text'])\n",
    "\n",
    "# Predict using Naive Bayes model\n",
    "nb_predictions = nb_model.predict(new_texts_tfidf)\n",
    "\n",
    "# Predict using Decision Tree model\n",
    "dt_predictions = dt_model.predict(new_texts_tfidf)\n",
    "\n",
    "# Print the predictions\n",
    "for i, text in enumerate(new_texts):\n",
    "    print(f\"Text: {text.strip()}\")\n",
    "    print(f\"Naive Bayes Prediction: {nb_predictions[i]}\")\n",
    "    print(f\"Decision Tree Prediction: {dt_predictions[i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66de21b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ಕನ್ನಡವೇನು\n",
      "Naive Bayes Prediction: Kannada\n",
      "Decision Tree Prediction: Kannada\n",
      "\n",
      "Text: தமிழ்நாடு\n",
      "Naive Bayes Prediction: Tamil\n",
      "Decision Tree Prediction: Tamil\n",
      "\n",
      "Text: తెలుగు భాష\n",
      "Naive Bayes Prediction: Telugu\n",
      "Decision Tree Prediction: Telugu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(new_texts):\n",
    "    print(f\"Text: {text.strip()}\")\n",
    "    print(f\"Naive Bayes Prediction: {nb_predictions[i]}\")\n",
    "    print(f\"Decision Tree Prediction: {dt_predictions[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cab490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
