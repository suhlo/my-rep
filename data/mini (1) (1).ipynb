{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0084a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1440 entries, 0 to 9048\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      1440 non-null   object\n",
      " 1   Language  1440 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 33.8+ KB\n",
      "None\n",
      "Telugu     494\n",
      "Tamil      489\n",
      "Kannada    457\n",
      "Name: Language, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (update the path as needed)\n",
    "df = pd.read_csv(\"C:/Users/Suhas sattigeri/Desktop/Mini P/data/dataset1.csv\")  # For dataset1\n",
    "# df = pd.read_csv(\"C:/Users/Suhas sattigeri/Desktop/Mini P/data/dataset2.csv\")  # For dataset2\n",
    "\n",
    "# Remove duplicate rows based on the 'Text' column\n",
    "df_cleaned = df.drop_duplicates(subset='Text', keep='first')\n",
    "\n",
    "# Save the cleaned dataset (optional)\n",
    "df_cleaned.to_csv(\"C:/Users/Suhas sattigeri/Desktop/Mini P/data/cleaned_dataset1.csv\", index=False)  # For dataset1\n",
    "# df_cleaned.to_csv(\"C:/Users/Suhas sattigeri/Desktop/Mini P/data/cleaned_dataset2.csv\", index=False)  # For dataset2\n",
    "\n",
    "# Check the new dataset size and distribution of languages\n",
    "print(df_cleaned.info())\n",
    "print(df_cleaned['Language'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313ab865-1bf7-4ed7-9f70-4329d46499e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3e2857-7090-4805-a180-7805af59b0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Text Language  word_count  character_count  word_density  \\\n",
      "0             தமிழ்நாடு    Tamil           1                9      0.100000   \n",
      "1  செய்தி தமிழ் இது ஒரு    Tamil           4               17      0.222222   \n",
      "2                நன்றி!    Tamil           1                6      0.142857   \n",
      "3              வணக்கம்!    Tamil           1                8      0.111111   \n",
      "4           மொழி தமிழ்?    Tamil           2               10      0.181818   \n",
      "\n",
      "   punc_count  num_vowels  vowel_density  num_exclamation_marks  \\\n",
      "0           0           0            0.0                      0   \n",
      "1           0           0            0.0                      0   \n",
      "2           1           0            0.0                      1   \n",
      "3           1           0            0.0                      1   \n",
      "4           1           0            0.0                      0   \n",
      "\n",
      "   num_question_marks  num_punctuation  num_unique_words  num_repeated_words  \\\n",
      "0                   0                0                 1                   0   \n",
      "1                   0                0                 4                   0   \n",
      "2                   0                1                 1                   0   \n",
      "3                   0                1                 1                   0   \n",
      "4                   1                1                 2                   0   \n",
      "\n",
      "   words_vs_unique  \n",
      "0              1.0  \n",
      "1              1.0  \n",
      "2              1.0  \n",
      "3              1.0  \n",
      "4              1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "# File path to the CSV file\n",
    "file_path = \"C:/Users/Suhas sattigeri/Desktop/Mini P/data/cleaned_dataset1.csv\"\n",
    "\n",
    "# Load the dataset with utf-8 encoding\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Remove null values for the \"Text\" column\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "# Convert the column \"Text\" to string type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "# Convert the column \"Language\" to string type\n",
    "df['Language'] = df['Language'].astype(str)\n",
    "\n",
    "# Define punctuation and vowels\n",
    "punc = ('.', ',', '!', '?', ';', ':', '-', '(', ')', '[', ']', '{', '}', \"'\", '\"')\n",
    "vowels = 'AEIOUaeiou'\n",
    "\n",
    "# Feature engineering\n",
    "df['word_count'] = df['Text'].apply(lambda x: len(x.split()))\n",
    "df['character_count'] = df['Text'].apply(lambda x: len(x.replace(\" \", \"\")))\n",
    "df['word_density'] = df['word_count'] / (df['character_count'] + 1)\n",
    "df['punc_count'] = df['Text'].apply(lambda x: len([a for a in x if a in punc]))\n",
    "df['num_vowels'] = df['Text'].apply(lambda x: sum([1 for a in x if a in vowels]))\n",
    "df['vowel_density'] = df['num_vowels'] / df['word_count']\n",
    "df['num_exclamation_marks'] = df['Text'].apply(lambda x: x.count('!'))\n",
    "df['num_question_marks'] = df['Text'].apply(lambda x: x.count('?'))\n",
    "df['num_punctuation'] = df['Text'].apply(lambda x: sum(x.count(w) for w in punc))\n",
    "df['num_unique_words'] = df['Text'].apply(lambda x: len(set(w for w in x.split())))\n",
    "df['num_repeated_words'] = df['Text'].apply(lambda x: len([w for w in collections.Counter(x.split()).values() if w > 1]))\n",
    "df['words_vs_unique'] = df['num_unique_words'] / df['word_count']\n",
    "\n",
    "# Display the first few rows of the dataframe to check the new features\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04a1bb1-4606-4944-acaf-be95ef57d01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language                 Kannada      Tamil     Telugu\n",
      "word_count              2.708972   2.748466   2.781377\n",
      "character_count        12.932166  16.073620  13.368421\n",
      "word_density            0.198075   0.167159   0.198044\n",
      "punc_count              0.678337   0.664622   0.665992\n",
      "num_vowels              0.000000   0.000000   0.000000\n",
      "vowel_density           0.000000   0.000000   0.000000\n",
      "num_exclamation_marks   0.339168   0.329243   0.340081\n",
      "num_question_marks      0.339168   0.335378   0.325911\n",
      "num_punctuation         0.678337   0.664622   0.665992\n",
      "num_unique_words        2.708972   2.748466   2.781377\n",
      "num_repeated_words      0.000000   0.000000   0.000000\n",
      "words_vs_unique         1.000000   1.000000   1.000000\n",
      "                       word_count  character_count  word_density  punc_count  \\\n",
      "word_count               1.000000         0.555618      0.416179    0.011054   \n",
      "character_count          0.555618         1.000000     -0.471111    0.106565   \n",
      "word_density             0.416179        -0.471111      1.000000   -0.144443   \n",
      "punc_count               0.011054         0.106565     -0.144443    1.000000   \n",
      "num_vowels                    NaN              NaN           NaN         NaN   \n",
      "vowel_density                 NaN              NaN           NaN         NaN   \n",
      "num_exclamation_marks    0.010361         0.058161     -0.073862    0.499987   \n",
      "num_question_marks       0.000648         0.048060     -0.070125    0.496878   \n",
      "num_punctuation          0.011054         0.106565     -0.144443    1.000000   \n",
      "num_unique_words         1.000000         0.555618      0.416179    0.011054   \n",
      "num_repeated_words            NaN              NaN           NaN         NaN   \n",
      "words_vs_unique               NaN              NaN           NaN         NaN   \n",
      "\n",
      "                       num_vowels  vowel_density  num_exclamation_marks  \\\n",
      "word_count                    NaN            NaN               0.010361   \n",
      "character_count               NaN            NaN               0.058161   \n",
      "word_density                  NaN            NaN              -0.073862   \n",
      "punc_count                    NaN            NaN               0.499987   \n",
      "num_vowels                    NaN            NaN                    NaN   \n",
      "vowel_density                 NaN            NaN                    NaN   \n",
      "num_exclamation_marks         NaN            NaN               1.000000   \n",
      "num_question_marks            NaN            NaN              -0.503128   \n",
      "num_punctuation               NaN            NaN               0.499987   \n",
      "num_unique_words              NaN            NaN               0.010361   \n",
      "num_repeated_words            NaN            NaN                    NaN   \n",
      "words_vs_unique               NaN            NaN                    NaN   \n",
      "\n",
      "                       num_question_marks  num_punctuation  num_unique_words  \\\n",
      "word_count                       0.000648         0.011054          1.000000   \n",
      "character_count                  0.048060         0.106565          0.555618   \n",
      "word_density                    -0.070125        -0.144443          0.416179   \n",
      "punc_count                       0.496878         1.000000          0.011054   \n",
      "num_vowels                            NaN              NaN               NaN   \n",
      "vowel_density                         NaN              NaN               NaN   \n",
      "num_exclamation_marks           -0.503128         0.499987          0.010361   \n",
      "num_question_marks               1.000000         0.496878          0.000648   \n",
      "num_punctuation                  0.496878         1.000000          0.011054   \n",
      "num_unique_words                 0.000648         0.011054          1.000000   \n",
      "num_repeated_words                    NaN              NaN               NaN   \n",
      "words_vs_unique                       NaN              NaN               NaN   \n",
      "\n",
      "                       num_repeated_words  words_vs_unique  \n",
      "word_count                            NaN              NaN  \n",
      "character_count                       NaN              NaN  \n",
      "word_density                          NaN              NaN  \n",
      "punc_count                            NaN              NaN  \n",
      "num_vowels                            NaN              NaN  \n",
      "vowel_density                         NaN              NaN  \n",
      "num_exclamation_marks                 NaN              NaN  \n",
      "num_question_marks                    NaN              NaN  \n",
      "num_punctuation                       NaN              NaN  \n",
      "num_unique_words                      NaN              NaN  \n",
      "num_repeated_words                    NaN              NaN  \n",
      "words_vs_unique                       NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Ensure all columns used for mean calculation are numerical\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Group by 'language' and calculate the mean, then transpose the result\n",
    "mean_by_language = df.groupby('Language')[numeric_columns].mean().T\n",
    "\n",
    "# Display the transposed result\n",
    "print(mean_by_language)\n",
    "\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the Pearson correlation matrix for numeric columns\n",
    "correlation_matrix = numeric_df.corr(method='pearson')\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2b5cd-ef11-407f-add6-74bfbf30154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49b0850f-cc8d-4ec0-a5a0-afdd85e80f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Split the dataset into features and target variable\n",
    "# Load the dataset with utf-8 encoding\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Remove null values for the \"text\" column\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "# Convert the column \"text\" to string type\n",
    "df['text'] = df['Text'].astype(str)\n",
    "\n",
    "# Convert the column \"language\" to string type\n",
    "df['Language'] = df['Language'].astype(str)\n",
    "\n",
    "# Remove rows where the text is empty or only whitespace\n",
    "df = df[df['Text'].str.strip() != '']\n",
    "\n",
    "# Features and labels\n",
    "X = df['Text']\n",
    "y = df['Language']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f7b654d-2287-4b9a-aca1-dbfc7d4af82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7847222222222222\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      0.81      0.89        93\n",
      "       Tamil       0.60      1.00      0.75        93\n",
      "      Telugu       1.00      0.57      0.72       102\n",
      "\n",
      "    accuracy                           0.78       288\n",
      "   macro avg       0.87      0.79      0.79       288\n",
      "weighted avg       0.87      0.78      0.79       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8423fe63-206b-4f5b-bab3-8276e339a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "Accuracy: 0.7847222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      0.81      0.89        93\n",
      "       Tamil       0.60      1.00      0.75        93\n",
      "      Telugu       1.00      0.57      0.72       102\n",
      "\n",
      "    accuracy                           0.78       288\n",
      "   macro avg       0.87      0.79      0.79       288\n",
      "weighted avg       0.87      0.78      0.79       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a03979-8fb3-4f99-94f4-e94a68a23ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier\n",
      "Accuracy: 0.9236111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      0.81      0.89        93\n",
      "       Tamil       1.00      0.96      0.98        93\n",
      "      Telugu       0.82      1.00      0.90       102\n",
      "\n",
      "    accuracy                           0.92       288\n",
      "   macro avg       0.94      0.92      0.92       288\n",
      "weighted avg       0.94      0.92      0.92       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dt = dt_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nDecision Tree Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "527124a4-7c2e-47db-9756-5335053bdac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Text Language  word_count  character_count  word_density  \\\n",
      "0             தமிழ்நாடு    Tamil           1                9      0.100000   \n",
      "1  செய்தி தமிழ் இது ஒரு    Tamil           4               17      0.222222   \n",
      "2                நன்றி!    Tamil           1                6      0.142857   \n",
      "3              வணக்கம்!    Tamil           1                8      0.111111   \n",
      "4           மொழி தமிழ்?    Tamil           2               10      0.181818   \n",
      "\n",
      "   punc_count  num_vowels  vowel_density  num_exclamation_marks  \\\n",
      "0           0           0            0.0                      0   \n",
      "1           0           0            0.0                      0   \n",
      "2           1           0            0.0                      1   \n",
      "3           1           0            0.0                      1   \n",
      "4           1           0            0.0                      0   \n",
      "\n",
      "   num_question_marks  num_punctuation  num_unique_words  num_repeated_words  \\\n",
      "0                   0                0                 1                   0   \n",
      "1                   0                0                 4                   0   \n",
      "2                   0                1                 1                   0   \n",
      "3                   0                1                 1                   0   \n",
      "4                   1                1                 2                   0   \n",
      "\n",
      "   words_vs_unique  \n",
      "0              1.0  \n",
      "1              1.0  \n",
      "2              1.0  \n",
      "3              1.0  \n",
      "4              1.0  \n",
      "Language                 Kannada      Tamil     Telugu\n",
      "word_count              2.708972   2.748466   2.781377\n",
      "character_count        12.932166  16.073620  13.368421\n",
      "word_density            0.198075   0.167159   0.198044\n",
      "punc_count              0.678337   0.664622   0.665992\n",
      "num_vowels              0.000000   0.000000   0.000000\n",
      "vowel_density           0.000000   0.000000   0.000000\n",
      "num_exclamation_marks   0.339168   0.329243   0.340081\n",
      "num_question_marks      0.339168   0.335378   0.325911\n",
      "num_punctuation         0.678337   0.664622   0.665992\n",
      "num_unique_words        2.708972   2.748466   2.781377\n",
      "num_repeated_words      0.000000   0.000000   0.000000\n",
      "words_vs_unique         1.000000   1.000000   1.000000\n",
      "                       word_count  character_count  word_density  punc_count  \\\n",
      "word_count               1.000000         0.555618      0.416179    0.011054   \n",
      "character_count          0.555618         1.000000     -0.471111    0.106565   \n",
      "word_density             0.416179        -0.471111      1.000000   -0.144443   \n",
      "punc_count               0.011054         0.106565     -0.144443    1.000000   \n",
      "num_vowels                    NaN              NaN           NaN         NaN   \n",
      "vowel_density                 NaN              NaN           NaN         NaN   \n",
      "num_exclamation_marks    0.010361         0.058161     -0.073862    0.499987   \n",
      "num_question_marks       0.000648         0.048060     -0.070125    0.496878   \n",
      "num_punctuation          0.011054         0.106565     -0.144443    1.000000   \n",
      "num_unique_words         1.000000         0.555618      0.416179    0.011054   \n",
      "num_repeated_words            NaN              NaN           NaN         NaN   \n",
      "words_vs_unique               NaN              NaN           NaN         NaN   \n",
      "\n",
      "                       num_vowels  vowel_density  num_exclamation_marks  \\\n",
      "word_count                    NaN            NaN               0.010361   \n",
      "character_count               NaN            NaN               0.058161   \n",
      "word_density                  NaN            NaN              -0.073862   \n",
      "punc_count                    NaN            NaN               0.499987   \n",
      "num_vowels                    NaN            NaN                    NaN   \n",
      "vowel_density                 NaN            NaN                    NaN   \n",
      "num_exclamation_marks         NaN            NaN               1.000000   \n",
      "num_question_marks            NaN            NaN              -0.503128   \n",
      "num_punctuation               NaN            NaN               0.499987   \n",
      "num_unique_words              NaN            NaN               0.010361   \n",
      "num_repeated_words            NaN            NaN                    NaN   \n",
      "words_vs_unique               NaN            NaN                    NaN   \n",
      "\n",
      "                       num_question_marks  num_punctuation  num_unique_words  \\\n",
      "word_count                       0.000648         0.011054          1.000000   \n",
      "character_count                  0.048060         0.106565          0.555618   \n",
      "word_density                    -0.070125        -0.144443          0.416179   \n",
      "punc_count                       0.496878         1.000000          0.011054   \n",
      "num_vowels                            NaN              NaN               NaN   \n",
      "vowel_density                         NaN              NaN               NaN   \n",
      "num_exclamation_marks           -0.503128         0.499987          0.010361   \n",
      "num_question_marks               1.000000         0.496878          0.000648   \n",
      "num_punctuation                  0.496878         1.000000          0.011054   \n",
      "num_unique_words                 0.000648         0.011054          1.000000   \n",
      "num_repeated_words                    NaN              NaN               NaN   \n",
      "words_vs_unique                       NaN              NaN               NaN   \n",
      "\n",
      "                       num_repeated_words  words_vs_unique  \n",
      "word_count                            NaN              NaN  \n",
      "character_count                       NaN              NaN  \n",
      "word_density                          NaN              NaN  \n",
      "punc_count                            NaN              NaN  \n",
      "num_vowels                            NaN              NaN  \n",
      "vowel_density                         NaN              NaN  \n",
      "num_exclamation_marks                 NaN              NaN  \n",
      "num_question_marks                    NaN              NaN  \n",
      "num_punctuation                       NaN              NaN  \n",
      "num_unique_words                      NaN              NaN  \n",
      "num_repeated_words                    NaN              NaN  \n",
      "words_vs_unique                       NaN              NaN  \n",
      "Accuracy: 0.7847222222222222\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      0.81      0.89        93\n",
      "       Tamil       0.60      1.00      0.75        93\n",
      "      Telugu       1.00      0.57      0.72       102\n",
      "\n",
      "    accuracy                           0.78       288\n",
      "   macro avg       0.87      0.79      0.79       288\n",
      "weighted avg       0.87      0.78      0.79       288\n",
      "\n",
      "Naive Bayes Classifier\n",
      "Accuracy: 0.7847222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      0.81      0.89        93\n",
      "       Tamil       0.60      1.00      0.75        93\n",
      "      Telugu       1.00      0.57      0.72       102\n",
      "\n",
      "    accuracy                           0.78       288\n",
      "   macro avg       0.87      0.79      0.79       288\n",
      "weighted avg       0.87      0.78      0.79       288\n",
      "\n",
      "\n",
      "Decision Tree Classifier\n",
      "Accuracy: 0.9236111111111112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      0.81      0.89        93\n",
      "       Tamil       1.00      0.96      0.98        93\n",
      "      Telugu       0.82      1.00      0.90       102\n",
      "\n",
      "    accuracy                           0.92       288\n",
      "   macro avg       0.94      0.92      0.92       288\n",
      "weighted avg       0.94      0.92      0.92       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import collections\n",
    "\n",
    "# File path to the CSV file\n",
    "file_path = \"C:/Users/Suhas sattigeri/Desktop/Mini P/data/cleaned_dataset1.csv\"\n",
    "\n",
    "# Load the dataset with utf-8 encoding\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Remove null values for the \"Text\" column\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "# Convert the column \"Text\" to string type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "# Convert the column \"Language\" to string type\n",
    "df['Language'] = df['Language'].astype(str)\n",
    "\n",
    "# Define punctuation and vowels\n",
    "punc = ('.', ',', '!', '?', ';', ':', '-', '(', ')', '[', ']', '{', '}', \"'\", \"\\\"\")\n",
    "\n",
    "vowels = 'AEIOUaeiou'\n",
    "\n",
    "# Feature engineering\n",
    "df['word_count'] = df['Text'].apply(lambda x: len(x.split()))\n",
    "df['character_count'] = df['Text'].apply(lambda x: len(x.replace(\" \", \"\")))\n",
    "df['word_density'] = df['word_count'] / (df['character_count'] + 1)\n",
    "df['punc_count'] = df['Text'].apply(lambda x: len([a for a in x if a in punc]))\n",
    "df['num_vowels'] = df['Text'].apply(lambda x: sum([1 for a in x if a in vowels]))\n",
    "df['vowel_density'] = df['num_vowels'] / df['word_count']\n",
    "df['num_exclamation_marks'] = df['Text'].apply(lambda x: x.count('!'))\n",
    "df['num_question_marks'] = df['Text'].apply(lambda x: x.count('?'))\n",
    "df['num_punctuation'] = df['Text'].apply(lambda x: sum(x.count(w) for w in punc))\n",
    "df['num_unique_words'] = df['Text'].apply(lambda x: len(set(w for w in x.split())))\n",
    "df['num_repeated_words'] = df['Text'].apply(lambda x: len([w for w in collections.Counter(x.split()).values() if w > 1]))\n",
    "df['words_vs_unique'] = df['num_unique_words'] / df['word_count']\n",
    "\n",
    "# Display the first few rows of the dataframe to check the new features\n",
    "print(df.head())\n",
    "\n",
    "# Ensure all columns used for mean calculation are numerical\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Group by 'language' and calculate the mean, then transpose the result\n",
    "mean_by_language = df.groupby('Language')[numeric_columns].mean().T\n",
    "\n",
    "# Display the transposed result\n",
    "print(mean_by_language)\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the Pearson correlation matrix for numeric columns\n",
    "correlation_matrix = numeric_df.corr(method='pearson')\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df['Text']\n",
    "y = df['Language']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dt = dt_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nDecision Tree Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63574117-d503-4d51-841b-2341fea3e218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
