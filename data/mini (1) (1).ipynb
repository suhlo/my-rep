{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313ab865-1bf7-4ed7-9f70-4329d46499e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3e2857-7090-4805-a180-7805af59b0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Text Language  word_count  character_count  word_density  \\\n",
      "0             தமிழ்நாடு    Tamil           1                9      0.100000   \n",
      "1  செய்தி தமிழ் இது ஒரு    Tamil           4               17      0.222222   \n",
      "2                நன்றி!    Tamil           1                6      0.142857   \n",
      "3              வணக்கம்!    Tamil           1                8      0.111111   \n",
      "4           மொழி தமிழ்?    Tamil           2               10      0.181818   \n",
      "\n",
      "   punc_count  num_vowels  vowel_density  num_exclamation_marks  \\\n",
      "0           0           0            0.0                      0   \n",
      "1           0           0            0.0                      0   \n",
      "2           1           0            0.0                      1   \n",
      "3           1           0            0.0                      1   \n",
      "4           1           0            0.0                      0   \n",
      "\n",
      "   num_question_marks  num_punctuation  num_unique_words  num_repeated_words  \\\n",
      "0                   0                0                 1                   0   \n",
      "1                   0                0                 4                   0   \n",
      "2                   0                1                 1                   0   \n",
      "3                   0                1                 1                   0   \n",
      "4                   1                1                 2                   0   \n",
      "\n",
      "   words_vs_unique  \n",
      "0              1.0  \n",
      "1              1.0  \n",
      "2              1.0  \n",
      "3              1.0  \n",
      "4              1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "# File path to the CSV file\n",
    "file_path = \"C:/Users/vidya/OneDrive/Desktop/extended_dataset.csv\"\n",
    "\n",
    "# Load the dataset with utf-8 encoding\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Remove null values for the \"Text\" column\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "# Convert the column \"Text\" to string type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "# Convert the column \"Language\" to string type\n",
    "df['Language'] = df['Language'].astype(str)\n",
    "\n",
    "# Define punctuation and vowels\n",
    "punc = ('.', ',', '!', '?', ';', ':', '-', '(', ')', '[', ']', '{', '}', \"'\", '\"')\n",
    "vowels = 'AEIOUaeiou'\n",
    "\n",
    "# Feature engineering\n",
    "df['word_count'] = df['Text'].apply(lambda x: len(x.split()))\n",
    "df['character_count'] = df['Text'].apply(lambda x: len(x.replace(\" \", \"\")))\n",
    "df['word_density'] = df['word_count'] / (df['character_count'] + 1)\n",
    "df['punc_count'] = df['Text'].apply(lambda x: len([a for a in x if a in punc]))\n",
    "df['num_vowels'] = df['Text'].apply(lambda x: sum([1 for a in x if a in vowels]))\n",
    "df['vowel_density'] = df['num_vowels'] / df['word_count']\n",
    "df['num_exclamation_marks'] = df['Text'].apply(lambda x: x.count('!'))\n",
    "df['num_question_marks'] = df['Text'].apply(lambda x: x.count('?'))\n",
    "df['num_punctuation'] = df['Text'].apply(lambda x: sum(x.count(w) for w in punc))\n",
    "df['num_unique_words'] = df['Text'].apply(lambda x: len(set(w for w in x.split())))\n",
    "df['num_repeated_words'] = df['Text'].apply(lambda x: len([w for w in collections.Counter(x.split()).values() if w > 1]))\n",
    "df['words_vs_unique'] = df['num_unique_words'] / df['word_count']\n",
    "\n",
    "# Display the first few rows of the dataframe to check the new features\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04a1bb1-4606-4944-acaf-be95ef57d01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language                Kannada      Tamil     Telugu\n",
      "word_count             1.725369   1.853042   1.853682\n",
      "character_count        9.908456  12.092960  10.828100\n",
      "word_density           0.161040   0.146488   0.159419\n",
      "punc_count             0.304295   0.306494   0.308202\n",
      "num_vowels             0.000000   0.000000   0.000000\n",
      "vowel_density          0.000000   0.000000   0.000000\n",
      "num_exclamation_marks  0.136242   0.132741   0.139686\n",
      "num_question_marks     0.168054   0.173753   0.168517\n",
      "num_punctuation        0.304295   0.306494   0.308202\n",
      "num_unique_words       1.725369   1.853042   1.853682\n",
      "num_repeated_words     0.000000   0.000000   0.000000\n",
      "words_vs_unique        1.000000   1.000000   1.000000\n",
      "                       word_count  character_count  word_density  punc_count  \\\n",
      "word_count               1.000000         0.704821      0.488300    0.468000   \n",
      "character_count          0.704821         1.000000     -0.224017    0.386519   \n",
      "word_density             0.488300        -0.224017      1.000000    0.172633   \n",
      "punc_count               0.468000         0.386519      0.172633    1.000000   \n",
      "num_vowels                    NaN              NaN           NaN         NaN   \n",
      "vowel_density                 NaN              NaN           NaN         NaN   \n",
      "num_exclamation_marks    0.241977         0.136943      0.149245    0.597631   \n",
      "num_question_marks       0.353262         0.349192      0.075540    0.681257   \n",
      "num_punctuation          0.468000         0.386519      0.172633    1.000000   \n",
      "num_unique_words         1.000000         0.704821      0.488300    0.468000   \n",
      "num_repeated_words            NaN              NaN           NaN         NaN   \n",
      "words_vs_unique               NaN              NaN           NaN         NaN   \n",
      "\n",
      "                       num_vowels  vowel_density  num_exclamation_marks  \\\n",
      "word_count                    NaN            NaN               0.241977   \n",
      "character_count               NaN            NaN               0.136943   \n",
      "word_density                  NaN            NaN               0.149245   \n",
      "punc_count                    NaN            NaN               0.597631   \n",
      "num_vowels                    NaN            NaN                    NaN   \n",
      "vowel_density                 NaN            NaN                    NaN   \n",
      "num_exclamation_marks         NaN            NaN               1.000000   \n",
      "num_question_marks            NaN            NaN              -0.179791   \n",
      "num_punctuation               NaN            NaN               0.597631   \n",
      "num_unique_words              NaN            NaN               0.241977   \n",
      "num_repeated_words            NaN            NaN                    NaN   \n",
      "words_vs_unique               NaN            NaN                    NaN   \n",
      "\n",
      "                       num_question_marks  num_punctuation  num_unique_words  \\\n",
      "word_count                       0.353262         0.468000          1.000000   \n",
      "character_count                  0.349192         0.386519          0.704821   \n",
      "word_density                     0.075540         0.172633          0.488300   \n",
      "punc_count                       0.681257         1.000000          0.468000   \n",
      "num_vowels                            NaN              NaN               NaN   \n",
      "vowel_density                         NaN              NaN               NaN   \n",
      "num_exclamation_marks           -0.179791         0.597631          0.241977   \n",
      "num_question_marks               1.000000         0.681257          0.353262   \n",
      "num_punctuation                  0.681257         1.000000          0.468000   \n",
      "num_unique_words                 0.353262         0.468000          1.000000   \n",
      "num_repeated_words                    NaN              NaN               NaN   \n",
      "words_vs_unique                       NaN              NaN               NaN   \n",
      "\n",
      "                       num_repeated_words  words_vs_unique  \n",
      "word_count                            NaN              NaN  \n",
      "character_count                       NaN              NaN  \n",
      "word_density                          NaN              NaN  \n",
      "punc_count                            NaN              NaN  \n",
      "num_vowels                            NaN              NaN  \n",
      "vowel_density                         NaN              NaN  \n",
      "num_exclamation_marks                 NaN              NaN  \n",
      "num_question_marks                    NaN              NaN  \n",
      "num_punctuation                       NaN              NaN  \n",
      "num_unique_words                      NaN              NaN  \n",
      "num_repeated_words                    NaN              NaN  \n",
      "words_vs_unique                       NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Ensure all columns used for mean calculation are numerical\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Group by 'language' and calculate the mean, then transpose the result\n",
    "mean_by_language = df.groupby('Language')[numeric_columns].mean().T\n",
    "\n",
    "# Display the transposed result\n",
    "print(mean_by_language)\n",
    "\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the Pearson correlation matrix for numeric columns\n",
    "correlation_matrix = numeric_df.corr(method='pearson')\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2b5cd-ef11-407f-add6-74bfbf30154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b0850f-cc8d-4ec0-a5a0-afdd85e80f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Split the dataset into features and target variable\n",
    "# Load the dataset with utf-8 encoding\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "# Remove null values for the \"text\" column\n",
    "df.dropna(subset=['Text'], inplace=True)\n",
    "\n",
    "# Convert the column \"text\" to string type\n",
    "df['text'] = df['Text'].astype(str)\n",
    "\n",
    "# Convert the column \"language\" to string type\n",
    "df['Language'] = df['Language'].astype(str)\n",
    "\n",
    "# Remove rows where the text is empty or only whitespace\n",
    "df = df[df['Text'].str.strip() != '']\n",
    "\n",
    "# Features and labels\n",
    "X = df['Text']\n",
    "y = df['Language']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7b654d-2287-4b9a-aca1-dbfc7d4af82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8226134055517942\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       0.65      1.00      0.79      1490\n",
      "       Tamil       1.00      0.88      0.94      1452\n",
      "      Telugu       1.00      0.59      0.74      1489\n",
      "\n",
      "    accuracy                           0.82      4431\n",
      "   macro avg       0.88      0.82      0.82      4431\n",
      "weighted avg       0.88      0.82      0.82      4431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8423fe63-206b-4f5b-bab3-8276e339a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier\n",
      "Accuracy: 0.8226134055517942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       0.65      1.00      0.79      1490\n",
      "       Tamil       1.00      0.88      0.94      1452\n",
      "      Telugu       1.00      0.59      0.74      1489\n",
      "\n",
      "    accuracy                           0.82      4431\n",
      "   macro avg       0.88      0.82      0.82      4431\n",
      "weighted avg       0.88      0.82      0.82      4431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a03979-8fb3-4f99-94f4-e94a68a23ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier\n",
      "Accuracy: 0.9036334913112164\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Kannada       1.00      0.83      0.91      1490\n",
      "       Tamil       1.00      0.88      0.94      1452\n",
      "      Telugu       0.78      1.00      0.87      1489\n",
      "\n",
      "    accuracy                           0.90      4431\n",
      "   macro avg       0.93      0.90      0.91      4431\n",
      "weighted avg       0.93      0.90      0.91      4431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dt = dt_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nDecision Tree Classifier\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b219b792-b1d6-48be-815f-bfea04f8b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ಕನ್ನಡವೇನು\n",
      "Naive Bayes Prediction: Kannada\n",
      "Decision Tree Prediction: Kannada\n",
      "\n",
      "Text: தமிழ்நாடு\n",
      "Naive Bayes Prediction: Tamil\n",
      "Decision Tree Prediction: Tamil\n",
      "\n",
      "Text: తెలుగు భాష \n",
      "Naive Bayes Prediction: Kannada\n",
      "Decision Tree Prediction: Telugu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example new text data\n",
    "new_texts = [\"ಕನ್ನಡವೇನು\", \"தமிழ்நாடு\", \"తెలుగు భాష \"]\n",
    "\n",
    "# Convert the new text data to a DataFrame\n",
    "new_df = pd.DataFrame(new_texts, columns=['Text'])\n",
    "\n",
    "# Preprocess the new text data\n",
    "new_df['Text'] = new_df['Text'].astype(str)\n",
    "new_df = new_df[new_df['Text'].str.strip() != '']\n",
    "\n",
    "# Transform the new text data using the same TF-IDF vectorizer\n",
    "new_texts_tfidf = vectorizer.transform(new_df['Text'])\n",
    "\n",
    "# Predict using Naive Bayes model\n",
    "nb_predictions = nb_model.predict(new_texts_tfidf)\n",
    "\n",
    "# Predict using Decision Tree model\n",
    "dt_predictions = dt_model.predict(new_texts_tfidf)\n",
    "\n",
    "# Print the predictions\n",
    "for i, text in enumerate(new_texts):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Naive Bayes Prediction: {nb_predictions[i]}\")\n",
    "    print(f\"Decision Tree Prediction: {dt_predictions[i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527124a4-7c2e-47db-9756-5335053bdac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e8b7a-86fc-4e56-a3aa-a04e3a74eda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63574117-d503-4d51-841b-2341fea3e218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
